import streamlit as st
st.set_page_config(layout="wide")
st.title("硬件方案")
st.subheader("1.GPU方案", divider=True)
st.write("英伟达的GPU在AI领域比较常用，在数据中心中H100以及下一代的B100等型号比较常用。不过在数据中心领域也有计算卡形式的AMD MI300、昇腾910b和使用SRAM的有带宽优势的Groq、Wafer Scale ENgine等竞品。在消费级中AMD的显卡低精度算力较低，比较少用，而英特尔的显卡算力性价比有优势。")
st.write("在适合个人用户的产品中，英伟达Tesla P40等二手计算卡因为价格低、显存大曾经在一般用户中有较高热度，但由于旧产品没有提高低精度算力的Tensor Core而开始使用Tensor Core的V100价格较高，个人用户大多使用消费级显卡运行算力需求较高的AI模型。")
st.write("一些英伟达消费级显卡由于有相同核心的大显存专业卡，可以通过改用单颗容量较大的显存或在PCB板背面加焊显存以搭载更多显存。其中最常用的是通过改焊单颗2g显存的2080ti 22g，虽然作为矿卡可靠性一般，但由于大显存且性价比高，有不少人使用。而无需改显存的大显存方案需要RTX3090。")
st.write("随着模型小型化和显存优化的发展，12g显存的显卡足以运行Deepcoder 14b和Wan2.1，绘画模型和其它类型的模型需要的显存更少，并且有一些性价比优于2080ti 22g的方案。16g显存的英特尔a770算力接近2080ti、价格低不少并且没有矿卡风险。12g显存的2060 12g降低了入门门槛。")
st.write("新一代显卡中由于B580 24g没有推出，显存提升均不明显。不过有一些高带宽核显方案，AMD的Strix Halo约256g内存带宽，考虑价格因素只适合用于规模特别大的模型。英伟达DGX Spark内存带宽接近但价格过高，反而比不上同价位的Mac。")

st.subheader("2.CPU方案", divider=True)
st.write("同代的同级别产品中，CPU的AI性能一般比GPU低不少。在二手产品中CPU在溢价较少的情况下仍需要更高成本达到与GPU方案相同的算力，但由于CPU方案扩展内存的成本较低，在运行大参数量LLM特别是MoE以及运行没有显存优化的视频模型时性价比较高。")
st.write("低于主流价位的方案主要是英特尔至强E5v3系列，由于支持ddr3内存，可以降低内存扩展成本，双路大约120g内存带宽。具体选择上，偏向性能的话双路2698bv3刚好64核，在Windows上可以避免分组。如果希望提高算力性价比，2666v3等型号有优势。")
st.write("主流价位以上的方案主要是AMD EPYC 7002系列，使用ddr4内存，单路或双路均为8通道大约400g内存带宽。其中性能最高的方案是使用双路共128核的7742，性能相当于RTX3090。接近主流价位的方案是单路7742（性能相当于2070Super）。")

st.subheader("3.手机和嵌入式设备", divider=True)
st.write("近期不少手机宣传AI功能。手机虽然算力和内存带宽较低，但也足以运行小规模的图像编辑和绘画模型。LLM方面，由于系统占用内存较大，8g内存只能运行3b模型，12g能运行7b，16g内存应该能运行14b模型。")
st.write("嵌入式设备中，通常使用NPU运行AI应用。瑞芯微的低端型号主要支持RNN，对LLM支持较好的有RK3576和RK3588，官方以及一些产品提供较为完整的资料。使用昇腾方案的有香橙派AI Pro系列，性价比低一些，虽然昇腾生态相对完善但该产品只提供了部署RNN的教程，其它应用可能因用户和社区支持较少导致难以部署。")

st.subheader("4.优势方案的变化", divider=True)
st.write("AI绘画在有优化的情况下显存需求不超过6g，AI视频方面比较早的CogVideoX 5b显存需求也不超过6g，后面的Hunyuan Video等模型显存需求较高，但比较新的模型中也有Wan2.1 1.3b等显存要求低的模型，较大的Wan2.1 14b也能在8g显存下生成33帧720p视频。")
st.write("LLM方面，Gemma2出现之前旗舰模型参数量较大，内存较大的非GPU方案仍值得考虑，但Gemma2 27b接近旗舰性能，Qwen2.5 32b正式达到旗舰性能，后面接近旗舰性能的Phi4只有14b参数量，适合单卡部署，又考虑到推理模型对生成速度要求较高，GPU方案就再次获得优势了。")
st.write("至于未来的优势方案。目前受需求到产品的滞后性、端侧AI应用实际需求不大以及需要兼顾其它应用等因素影响，当前的AI硬件不是最佳形态。后续如果AI应用需求扩大且游戏等应用能改用纯AI形式，在GPU/SoC中的低精度张量部分会使用更大面积以提高算力，显存容量和带宽也有望进一步提高。")

st.subheader("5.当前的硬件的问题", divider=True)
st.write("当前的消费级硬件大多没有充分考虑AI用途，向量计算单元面积较小或没有向大显存、高带宽方向发展。出现这一现象一方面原因是企业注重利润以及偏向数据中心市场，另一方面原因是用户多且具有较高性能要求的有需求的端侧AI应用较少。")

